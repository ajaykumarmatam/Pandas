df.dropna()
#it will remove drop records whereever NAN values present .
#by default axis=0 means it will remove row records by default 


df.dropna(axis=1)
#it will remove columns which NaN values 


axis =0 ---> row level

axis =1 --->column level


How to check how many null value each column does have :
========================================================

df.isnull().sum()


============================================================================================================
inplace(False) attribute in dropna()

By defalut inplace(False)

df.dropna()  # after performing dropna() ,again if we run df removed NaN values will come into data frame means NaN values gets deleted temporily .if we want to delete permenantly we have two ways .

one way:
=======
df=df.dropna()  override df

second way:
===========
df.dropna(inplace=True)



=============================================================================================================

thresh():
========
df.dropna(axis=1)
#it will remove columns which NaN values 
#It will remove columns even column does have sinle NaN value

requiremnt : delete column which has more than 10 NaN values.

df.dropna(axis=1,thresh=800)

thresh=800 ---. it requires 800 non NaN value records. if 800 non NaN values are not there it will remove that column 


============================================================================================================

how()

df.dropna(axis=1,how="all")
#it will remove column which does have all NaN values

df.dropna(axis=0,how="all")
#it will remove row records which does have all NaN values 

============================================================================================================

fillna()
=========

df.fillna(value="ajay")
#it will replace records

objective:
==========
fill NaN values with average of age column [but this is practice ,In real time we dont replace NaN values with average of some other column 

df.fillna(value=df["Age"].mean())

Replace NaN values of specific column with median of that column
=================================================================

df["Age"]=df["Age"].fillna(df["Age"].median())

df

=============================================================================================================
transpose():
==========

============================================================================================================
concat():
=========
pd.concat([df1,df2])
#perform row wise concatination 

pd.concat([df1,df3],axis=1)
#It will perform column wise concatination 
#it will concat two dfs based on index

===============================================================================================================
iloc[]  --- integerlocation 

iloc works based on inbuilt index not a named one 


df.iloc[:,3]
#it gives all row records of 3 rd column 

df.iloc[:,[3,4,5]]
#it gives all the row records of 3,4,and 5th column 

df.iloc[[5,6],[3,4,5]]
#it gives 5,6 th row records of 3,4 and 5th column 

df.loc[[3,4],["Age"]]
#it gives 3,4 th row records of age column

=============================================================================================================
loc[]  -location 

loc words based on named index 

df.loc[[3,4],["Age"]]
#it gives 3,4 th row records of age column

=============================================================================================================
merge operations :
==================

How concatination different from merge:
=======================================

example:
========
df1

id age name city 

1   30  ajay  atp

2   40  kumar  ukd


df2

id age name city 

1   35  naven krnl


2   40  ravi bnn


pd.merge(df1,df2,on="age")

result:

id age  x_name    x_city   y_name   y_city
2  40    kumar    ukd     ravi      bnn 



"how" attribute in merger()
==========================
there types of merge operations 

1)inner 
2)right
3)left
4)outer

by default inner  considered 

If we want to use other merges we have to specify those in "how" 


pd.merge(df1,df2,on="age",how="left")   # matching records from both tables  and all the records from left table
pd.merge(df1,df2,on="age",how="right")  #matching records from both tables and all the records from right table




To rename column names :
=========================
df.rename(columns={job:job1,name:name1},inplace=True)


set_index():
===========
convert column into index  

df.set_index("age)  #age column become first index 


joins :
======








Creating DataFrame by using Dictionareies
=========================================

Each key will be created as column 

and Each element in list of dictionaly value created as one row

pd.DataFrame({"col1":[1,2,3,4,5],
              "col2":[12,13,14,15,16],
              "col3": "ajay kumar matam meen kenekal"})


col1	col2	col3
0	1	12	ajay kumar matam meen kenekal
1	2	13	ajay kumar matam meen kenekal
2	3	14	ajay kumar matam meen kenekal
3	4	15	ajay kumar matam meen kenekal
4	5	16	ajay kumar matam meen kenekal


Here I dont want store in col3 for each row as "	ajay kumar matam meen kenekal" .To split string we have to use 
split()

df=pd.DataFrame({"col1":[1,2,3,4,5],
              "col2":[12,13,14,15,16],
              "col3": "ajay kumar matam meen kenekal".split()})

df

col1	col2	col3
0	1	12	ajay
1	2	13	kumar
2	3	14	matam
3	4	15	meen
4	5	16	kenekal




REquiremnt : I want to create new column to above df and nwe column data would be square of first column 

df["col4"]=df["col1"]**2

df

col1	col2	col3	col4
0	1	12	ajay	1
1	2	13	kumar	4
2	3	14	matam	9
3	4	15	meen	16
4	5	16	kenekal	25

or by using apply function :
============================
def test(a):
    return a**2

df["col4_4]=df["col1"].apply(test)


Requirement : I want to create new column with first character of column number 3 

df["col5"]=df["col3"].str[0]

	col1	col2	col3	col4	col5
0	1	12	ajay	1	a
1	2	13	kumar	4	k
2	3	14	matam	9	m
3	4	15	meen	16	m
4	5	16	kenekal	25	k

Requirement : Create new column witj below conditon
if previous column value is a then keep a in new column other wise keep z .


By using apply function()
===========================
apply is kind of mapper and it will be applicable to each and every element available in list of column 

def test(i):
  if i=='a':
    return i
  else:
    return 'z'

df["col6"]=df['col5'].apply(test)

	col1	col2	col3	col4	col5	col6
0	1	     12	  ajay	 1	     a	   a
1	2	     13	  kumar	 4	     k	   z
2	3	     14	  matam	 9	     m	   z
3	4	     15	  meen	 16	     m	   z
4	5	     16	kenekal	    25	 k	   z



By using lambda function by avoiding external functions :
========================================================
we can use lambda function if logic is very easy

df["col6_6"]=df["col5"].apply(lambda x : 'a' if x=='a' else 'z')

	col1	col2	col3	col4	col5	col6	col6_6
0	1	12	ajay	1	a	a	a
1	2	13	kumar	4	k	z	z
2	3	14	matam	9	m	z	z
3	4	15	meen	16	m	z	z
4	5	16	kenekal	25	k	z	z



Requirement : 
-------------
Create new column with length of column 3

df["col7"]=df["col3"].apply(len)

df

col1	col2	col3	col4	col5	col6	     col6_6  col7
0	1	12	ajay	1	a	a	a	4
1	2	13	kumar	4	k	z	z	5
2	3	14	matam	9	m	z	z	5
3	4	15	meen	16	m	z	z	4
4	5	16	kenekal	25	k	z	z	7




Requireement : 
Create new column with log values of col2 

log function not available in python. 

So we have to first import math module 

import math

df["col8"]=df["col2"].apply(math.log)


col1	col2	col3	col4	col5	col6	col6_6	      col7	   col8
0	1	12	ajay	1	a	a	a	4	2.484907
1	2	13	kumar	4	k	z	z	5	2.564949
2	3	14	matam	9	m	z	z	5	2.639057
3	4	15	meen	16	m	z	z	4	2.708050
4	5	16	kenekal	25	k	z	z	7	2.772589


