Pandas : 

Pandas is a library in python used for accessing,updating,modifying and ect data 

Pandas can handle different kind of file formats 


How to read csv file data using pandas : 
========================================

import pandas as pd 

pd.read_csv("filename")

Some time while reading we may get below error because windows os 

pd.read_csv("C:\Users\0027UG744\Desktop\StudentData.csv")

 File "C:\Users\0027UG744\AppData\Local\Temp\ipykernel_27176\4077957699.py", line 1
    pd.read_csv("C:\Users\0027UG744\Desktop\StudentData.csv")
                                                            ^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape


to avoid above error messages we have to use 'r' like below while reading 

pd.read_csv(r"C:\Users\0027UG744\Desktop\StudentData.csv")


pandas will consider first row as columns .if we dont want to consider first row as columns then we should use header=None parameter while reading 

pd.read_csv("filename",header=None)

if we use header=None, header columns will be displayed as 0,1,2,3......

if we dont want to header to be dispalyed as 0,1,2,3,4... ,we use names=['a','b','c','d']

 pd.read_csv("filename",names=['a','b','c','d'])

example : 
pd.read_csv(r"C:\Users\0027UG744\Desktop\StudentData.csv",names=['a','b','c','d','e','f','g'])



Pandas will by deafult seperate comma seperated value(csv) ",". 

If columns are seperated by rather than ",".we have to use sep='@',sep="|"

pd.read_csv("filename",sep="@")

if columns are seperate by "|"

pd.read_csv("filename",sep="|")


=>Some time we may want skip some rows then we have to use skiprows=[row1,row3]

pd.read_csv("filename",sep="|",skiprows=[1,5])


=>pd.read_csv("filename")  -> returns dataframe ->which table structure in pandas

df1=pd.read_csv("filename")

type(df1)    # returns datatypes of each column 



=>String values are represented as Objects in pandas 

head():
It will return first records 

=>df.head() 


head(2) :

it will return first two records from dataset

=df.head(2)

tail(): 

It will return last 5 records 
df.tail()

tail(2):

It will return last 2 records 
df.tail(2)


=>To get list of columns 
df.columns 

=>lets suppose there are many columns we are not intrested in those many columns .we want to get only a few 

df['email']


a=df["name"]
a
type(a)
pandas.core.series.Series

Series :  when we get one column+one row

dataframe : collection of multiple series 

==================================================================================================

a=df["name","gender"]


---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~\Anaconda3\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance)
   3628             try:
-> 3629                 return self._engine.get_loc(casted_key)
   3630             except KeyError as err:

~\Anaconda3\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc()

~\Anaconda3\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: ('name', 'gender')

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_27176\3927833831.py in <module>
----> 1 a=df["name","gender"]

~\Anaconda3\lib\site-packages\pandas\core\frame.py in __getitem__(self, key)
   3503             if self.columns.nlevels > 1:
   3504                 return self._getitem_multilevel(key)
-> 3505             indexer = self.columns.get_loc(key)
   3506             if is_integer(indexer):
   3507                 indexer = [indexer]

~\Anaconda3\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance)
   3629                 return self._engine.get_loc(casted_key)
   3630             except KeyError as err:
-> 3631                 raise KeyError(key) from err
   3632             except TypeError:
   3633                 # If we have a listlike key, _check_indexing_error will raise

KeyError: ('name', 'gender')




a=df.[["name","gender"]]


type(df[["name"]])

pandas.core.frame.DataFrame

when you pass even single column as list then it is an dataframe

when you pass single column as column then it is series 





How to fetch csv data from github :
==================================

pd.read_csv("https://raw.githubusercontent.com/codeforamerica/ohana-api/master/data/sample-csv/addresses.csv")

Note: you have to click raw in github before loading data from github






Pandas part 2: 

==============

Reading tables from webpages :
===========================
import pandas as pd 

df=pd.read_html("https://www.basketball-reference.com/leagues/NBA_2015_totals.html")

type(df)  # it returns list not a dataframe



after loading data from web page we want data to be in readable format means in table format 

len(list) # it returns 1  means there is 1 table available in list [only 1 index available in list]

type(df[0]) # it returns datframe read

waht we can say from above is data which in list at 0 index is dataframe


What read_html does ? and limitation of read_html:
================================================

It will read data from webpages only data availale in tr/table tags 

It wont read all the images and other things available in web pages 


why we need to read data from web pages : 

========================================
when ever we build a model your internal data set is sufficiant enough so we havr to acquire data from some external source or open source or may be from 

web pages for this we do.


Example:
========

df=pd.read_html("https://www.basketball-reference.com/leagues/NBA_2015_totals.html")

type(df) 

df1=df[0]

df1.columns 

df1.head()

df1.tail()

df1.head(3)


How to save data from jupitar notebook into local :
==================================================
pd.to_csv("pathlocation\filename")


pandas will generate index by deafault .if we dont want pandas to generate index 

pd.to_csv("filename",index=False)

Example:
=======



PANDAS AND JSON :
================
Every time when we get josn we have to verrify whether json file is valid or not by using online tooks like jsonschemavalidator 

Convert json files into tabular format:
=======================================
=>String can not be converted into DataFrame

d="""
{
"name":"ajay kumar",
"gmail":"ajaykumar.matam@gmail.com",
"tech":["testing","bigdata"]
}
"""

Example:

import pandas as pd
pd.DataFrame(d)

o.p:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_20508\2567112034.py in <module>
----> 1 pd.DataFrame(d)

~\Anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy)
    754         else:
    755             if index is None or columns is None:
--> 756                 raise ValueError("DataFrame constructor not properly called!")
    757 
    758             # Argument 1 to "ensure_index" has incompatible type "Collection[Any]";

ValueError: DataFrame constructor not properly called!

Note: we can not convert string into dataframe directly 

we have to follow below:
==========================

example:

import pandas as pd

d="""
{
"name":"ajay kumar",
"gmail":"ajaykumar.matam@gmail.com",
"tech":["testing","bigdata"]
}
"""
typs(d)  #str
import json

d1=json.loads(d)

type(d1)  #dict

pd.DataFrame(d1)

o/p:

name	gmail	tech
0	ajay kumar	ajaykumar.matam@gmail.com	testing
1	ajay kumar	ajaykumar.matam@gmail.com	bigdata


Example: 
========
With in json lets say there are two lists .if two lists item count is not equal then we cannot convert into DataFrame

Example:

import pandas as pd 

d="""
{
"name":"ajay kumar",
"gmail":"ajaykumar.matam@gmail.com",
"tech":["testing","bigdata"],
"platform":["qaedge"]
}
"""

import json

d1=json.loads(d)

pd.DataFrame(d1)

#will get below error 

o/p:

ValueError                                Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_20508\3376031797.py in <module>
----> 1 pd.DataFrame(d1)

~\Anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy)
    634         elif isinstance(data, dict):
    635             # GH#38939 de facto copy defaults to False only in non-dict cases
--> 636             mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
    637         elif isinstance(data, ma.MaskedArray):
    638             import numpy.ma.mrecords as mrecords

~\Anaconda3\lib\site-packages\pandas\core\internals\construction.py in dict_to_mgr(data, index, columns, dtype, typ, copy)
    500         # TODO: can we get rid of the dt64tz special case above?
    501 
--> 502     return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)
    503 
    504 

~\Anaconda3\lib\site-packages\pandas\core\internals\construction.py in arrays_to_mgr(arrays, columns, index, dtype, verify_integrity, typ, consolidate)
    118         # figure out the index, if necessary
    119         if index is None:
--> 120             index = _extract_index(arrays)
    121         else:
    122             index = ensure_index(index)

~\Anaconda3\lib\site-packages\pandas\core\internals\construction.py in _extract_index(data)
    672             lengths = list(set(raw_lengths))
    673             if len(lengths) > 1:
--> 674                 raise ValueError("All arrays must be of the same length")
    675 
    676             if have_dicts:

ValueError: All arrays must be of the same length


Note: so make lists inside json must be in same length
example:2

import pandas as pd

d="""
{
"name":"ajay kumar",
"gmail":"ajaykumar.matam@gmail.com",
"tech":["testing","bigdata"],
"platform":["qaedge","ineroun"]
}
"""

import json

d1=json.loads(d)

pd.DataFrame(d1)

o/p:
name	gmail	tech	platform
0	ajay kumar	ajaykumar.matam@gmail.com	testing	qaedge
1	ajay kumar	ajaykumar.matam@gmail.com	bigdata	ineroun



ad










